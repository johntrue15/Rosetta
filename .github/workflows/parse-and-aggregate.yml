name: Parse & Aggregate Data

on:
  push:
    paths:
      - "data/**"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: parse-and-aggregate-${{ github.ref }}
  cancel-in-progress: false

jobs:
  parse:
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, '[skip ci]')"

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install striprtf
          if [ -f scripts/requirements.txt ]; then
            pip install -r scripts/requirements.txt
          fi

      - name: Ensure output folders exist
        run: |
          mkdir -p data/parsed
          mkdir -p data/completed

      - name: Determine changed source files
        id: changed
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"

          if [ -z "${BEFORE}" ] || [ "${BEFORE}" = "0000000000000000000000000000000000000000" ]; then
            git ls-files 'data/**' \
            | grep -v -E '\.json$' \
            | grep -v -E '^data/parsed/' \
            | grep -v -E '^data/completed/' \
            > changed.txt || true
          else
            git diff --name-only "${BEFORE}" "${{ github.sha }}" -- 'data/**' \
            | grep -v -E '\.json$' \
            | grep -v -E '^data/parsed/' \
            | grep -v -E '^data/completed/' \
            > changed.txt || true
          fi

          echo "Changed candidate files:"
          cat changed.txt || true
          echo "list=$(pwd)/changed.txt" >> "$GITHUB_OUTPUT"

      - name: Parse changed files â†’ JSON (via scripts/parse_any.py)
        if: ${{ always() && steps.changed.outputs.list != '' }}
        shell: bash
        run: |
          set -euo pipefail
          LIST_FILE="${{ steps.changed.outputs.list }}"

          if [ ! -s "$LIST_FILE" ]; then
            echo "No source files to parse."
            exit 0
          fi

          while IFS= read -r f; do
            [ -z "${f:-}" ] && continue
            [ ! -f "$f" ] && continue
            echo "Parsing: $f"
            python scripts/parse_any.py "$f" \
              -o data/parsed \
              --completed-dir data/completed \
              --pretty
          done < "$LIST_FILE"

          # Safety cleanup: remove any leftover metadata sources outside parsed/completed
          find data -type f \
            ! -path "data/parsed/*" \
            ! -path "data/completed/*" \
            \( -iname "*.rtf" -o -iname "*.pca" -o -iname "*.xtekct" -o -iname "*.xml" \) \
            -print -exec rm -f {} +

      - name: Aggregate & de-duplicate metadata
        shell: bash
        run: |
          set -euo pipefail
          if [ -f scripts/aggregate_json.py ]; then
            # Use script defaults (writes to data/metadata.json)
            python scripts/aggregate_json.py
          else
            echo "scripts/aggregate_json.py not found!" >&2
            exit 1
          fi

      - name: Commit & push results
        shell: bash
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add -A data/parsed
          git add -A data/completed
          git add -A data/metadata.json

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Parse & aggregate data [skip ci]"
          git push
