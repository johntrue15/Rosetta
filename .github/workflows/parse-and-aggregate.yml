name: Parse & Aggregate Data

on:
  push:
    # Keep this simple; we'll filter JSON in the job logic
    paths:
      - 'data/**'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: parse-and-aggregate-${{ github.ref }}
  cancel-in-progress: false

jobs:
  parse:
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, '[skip ci]')"

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install core parser deps
        run: |
          python -m pip install --upgrade pip
          pip install striprtf xmltodict pandas

      - name: Install extra parser deps (optional)
        run: |
          if [ -f scripts/requirements.txt ]; then
            pip install -r scripts/requirements.txt
          fi

      - name: Ensure output dirs exist
        run: |
          mkdir -p data/parsed
          mkdir -p data

      - name: Determine changed source files (ignore *.json)
        id: changed
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"
          if [ -z "${BEFORE}" ] || [ "${BEFORE}" = "0000000000000000000000000000000000000000" ]; then
            files=$(git ls-files 'data/**' | grep -v -E '\.json$' || true)
          else
            files=$(git diff --name-only "${BEFORE}" "${{ github.sha }}" -- 'data/**' | grep -v -E '\.json$' || true)
          fi
          echo "Changed files:"
          printf '%s\n' "$files"
          echo "FILES=$(printf '%s\n' "$files" | paste -sd "," -)" >> $GITHUB_ENV

      - name: Parse changed files â†’ JSON (append .json to original filename)
        if: env.FILES != ''
        shell: bash
        run: |
          set -euo pipefail
          IFS=',' read -ra arr <<< "$FILES"
          for f in "${arr[@]}"; do
            [ -z "$f" ] && continue
            [ ! -f "$f" ] && continue
            echo "Parsing: $f"
            python scripts/parse_any.py "$f" --outdir data/parsed --pretty
          done

      - name: Aggregate & append to metadata.json (cumulative)
        shell: bash
        run: |
          set -euo pipefail
          python scripts/aggregate_metadata.py --parsed-dir data/parsed --out data/metadata.json

      - name: Commit & push results
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          # Ensure folders exist (idempotent)
          mkdir -p data/parsed
          mkdir -p data
          git add -A data/parsed
          git add data/metadata.json 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Parse & aggregate data (append) [skip ci]"
          git push
