name: Parse & Aggregate Data

on:
  push:
    # Watch all content under data/**, but ignore JSON to avoid loops
    paths:
      - 'data/**'
    paths-ignore:
      - 'data/**/*.json'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: parse-and-aggregate-${{ github.ref }}
  cancel-in-progress: false

jobs:
  parse:
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, '[skip ci]')"

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install core parser deps
        run: |
          python -m pip install --upgrade pip
          pip install striprtf

      - name: Install extra parser deps (optional)
        run: |
          if [ -f scripts/requirements.txt ]; then
            pip install -r scripts/requirements.txt
          fi

      - name: Determine changed source files
        id: changed
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"
          if [ -z "${BEFORE}" ] || [ "${BEFORE}" = "0000000000000000000000000000000000000000" ]; then
            files=$(git ls-files 'data/**' | grep -v -E '\.json$' || true)
          else
            files=$(git diff --name-only "${BEFORE}" "${{ github.sha }}" -- 'data/**' | grep -v -E '\.json$' || true)
          fi
          echo "Changed files:"
          printf '%s\n' "$files"
          echo "FILES=$(printf '%s\n' "$files" | paste -sd "," -)" >> $GITHUB_ENV

      - name: Parse changed files â†’ JSON (known types + generic fallback)
        if: env.FILES != ''
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data/parsed

          # One generic wrapper to avoid repeating heredocs (and YAML errors)
          generic_wrap() {
            python - "$1" "$2" <<'PY'
import sys, json, os, base64, hashlib
p, out = sys.argv[1], sys.argv[2]
info = {
    "source_path": p,
    "filename": os.path.basename(p),
    "extension": os.path.splitext(p)[1].lstrip('.'),
    "size_bytes": os.path.getsize(p),
    "sha256": hashlib.sha256(open(p, 'rb').read()).hexdigest(),
}
try:
    txt = open(p, 'r', encoding='utf-8').read()
    info["content_text"] = txt
    info["encoding"] = "utf-8"
except Exception:
    raw = open(p, 'rb').read()
    info["content_base64"] = base64.b64encode(raw).decode('ascii')
    info["encoding"] = "base64"
os.makedirs(os.path.dirname(out), exist_ok=True)
json.dump(info, open(out, 'w', encoding='utf-8'), ensure_ascii=False, indent=2)
PY
          }

          IFS=',' read -ra arr <<< "$FILES"
          for f in "${arr[@]}"; do
            [ -z "$f" ] && continue
            [ ! -f "$f" ] && continue

            base="$(basename "$f")"
            stem="${base%.*}"
            ext="${f##*.}"
            lc_ext="$(echo "$ext" | tr '[:upper:]' '[:lower:]')"
            out="data/parsed/${stem}.json"

            case "$lc_ext" in
              rtf)
                # Use integrated RTF parser
                python scripts/rtf_to_json.py "$f" -o "$out" --pretty
                ;;
              xml)
                if [ -f scripts/xml_to_json.py ]; then
                  if ! python scripts/xml_to_json.py "$f" -o "$out"; then
                    echo "XML parser failed, falling back to generic for: $f"
                    generic_wrap "$f" "$out"
                  fi
                else
                  echo "No XML parser found; using generic for: $f"
                  generic_wrap "$f" "$out"
                fi
                ;;
              pca)
                if [ -f scripts/pca_to_json.py ]; then
                  if ! python scripts/pca_to_json.py "$f" -o "$out"; then
                    echo "PCA parser failed, falling back to generic for: $f"
                    generic_wrap "$f" "$out"
                  fi
                else
                  echo "No PCA parser found; using generic for: $f"
                  generic_wrap "$f" "$out"
                fi
                ;;
              *)
                # Generic fallback for ANY other metadata file type
                echo "Using generic wrapper for: $f"
                generic_wrap "$f" "$out"
                ;;
            esac
          done

      - name: Aggregate & de-duplicate metadata
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import os, json, glob, hashlib
          OUT = 'data/metadata.json'
          records = {}
          for path in glob.glob('data/**/*.json', recursive=True):
              if os.path.normpath(path) == os.path.normpath(OUT):
                  continue
              try:
                  with open(path, 'r', encoding='utf-8') as f:
                      data = json.load(f)
              except Exception:
                  continue
              items = data if isinstance(data, list) else [data]
              for item in items:
                  if not isinstance(item, dict):
                      item = {"_raw": data, "source_path": path}
                  key = None
                  for k in ('id','uuid','source','source_path','filename'):
                      if k in item and item[k] is not None:
                          key = f"{k}:{item[k]}"
                          break
                  if key is None:
                      key = hashlib.sha256(
                          json.dumps(item, sort_keys=True, ensure_ascii=False).encode('utf-8')
                      ).hexdigest()
                  records[key] = item
          os.makedirs(os.path.dirname(OUT), exist_ok=True)
          with open(OUT, 'w', encoding='utf-8') as f:
              json.dump(list(records.values()), f, ensure_ascii=False, indent=2)
          PY

      - name: Commit & push results
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/parsed/**/*.json 2>/dev/null || true
          git add data/metadata.json 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Parse & aggregate data [skip ci]"
          git push
