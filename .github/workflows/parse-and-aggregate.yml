name: Parse & Aggregate Data

on:
  push:
    paths:
      - 'data/**'
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: parse-and-aggregate-${{ github.ref }}
  cancel-in-progress: false

jobs:
  parse:
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, '[skip ci]')"

    steps:
      - name: Check out repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install core parser deps
        run: |
          python -m pip install --upgrade pip
          pip install striprtf pandas

      - name: Install extra parser deps (optional)
        run: |
          if [ -f scripts/requirements.txt ]; then
            pip install -r scripts/requirements.txt
          fi

      - name: Ensure output folders exist
        run: |
          mkdir -p data/parsed
          mkdir -p data/completed

      - name: Determine changed source files (exclude JSON, parsed, completed)
        id: changed
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"
          if [ -z "${BEFORE}" ] || [ "${BEFORE}" = "0000000000000000000000000000000000000000" ]; then
            files=$(git ls-files 'data/**' || true)
          else
            files=$(git diff --name-only "${BEFORE}" "${{ github.sha }}" -- 'data/**' || true)
          fi

          # Exclude JSON outputs and the parsed/completed folders
          files=$(printf '%s\n' "$files" \
            | grep -v -E '\.json$' \
            | grep -v -E '^data/(parsed|completed)/' \
            || true)

          echo "Changed files:"
          printf '%s\n' "$files"
          echo "FILES=$(printf '%s\n' "$files" | paste -sd "," -)" >> $GITHUB_ENV

      - name: Parse changed files â†’ JSON (and move originals)
        if: env.FILES != ''
        shell: bash
        run: |
          set -euo pipefail
          IFS=',' read -ra arr <<< "$FILES"
          for f in "${arr[@]}"; do
            [ -z "$f" ] && continue
            [ ! -f "$f" ] && continue
            # Run as a module so 'from scripts.*' imports work
            python -m scripts.parse_any "$f" -o data/parsed --completed-dir data/completed --pretty
          done

      - name: Aggregate & de-duplicate metadata cumulatively
        shell: bash
        run: |
          set -euo pipefail
          python -m scripts.aggregate_metadata --out data/metadata.json

      - name: Commit & push results
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          mkdir -p data/parsed data/completed
          git add -A data/parsed
          git add -A data/completed
          git add data/metadata.json 2>/dev/null || true
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Parse & aggregate data [skip ci]"
          git push
